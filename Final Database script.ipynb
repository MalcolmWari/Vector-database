{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define a transform to normalize the data. The transforms are applied\n",
    "# in the order they are given. First, the image is converted to a tensor,\n",
    "# then it is normalized with mean and standard deviation of 0.5 for all channels.\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Download the CIFAR-10 dataset, apply the transforms, and load it into\n",
    "# a DataLoader for efficient batch processing and shuffling.\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=0)\n",
    "\n",
    "# Define the classes in the CIFAR-10 dataset. These correspond to the labels\n",
    "# of the images in the dataset.\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Load the pretrained ResNet-50 model.\n",
    "net = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze all the parameters of the model, making them untrainable.\n",
    "# This is done because we want to keep the weights of the pre-trained model\n",
    "# and only train the final layer that we will add next.\n",
    "for param in net.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the last fully connected layer of the model with a new one \n",
    "# having the correct number of output features. The new layer's parameters\n",
    "# are not frozen, so they will be learned during training.\n",
    "num_ftrs = net.fc.in_features\n",
    "net.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "# Define a loss function and an optimizer. The loss function is used to measure\n",
    "# how well the model's predictions match the actual labels, and the optimizer\n",
    "# is used to update the model's parameters based on this loss.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Set device to GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move the model to the device (GPU or CPU)\n",
    "net.to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(5):  # Loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get the inputs; data is a list of [inputs, labels]\n",
    "        # Move the inputs and labels to the device\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        # This is necessary because by default, gradients are accumulated\n",
    "        # in backward passes, so we need to clear them at each step\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass: compute the outputs by passing inputs to the model\n",
    "        outputs = net(inputs)\n",
    "        # Compute the loss between the outputs and the ground truth labels\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backward pass: compute the gradients of the loss w.r.t. the model's parameters\n",
    "        loss.backward()\n",
    "        # Perform an optimization step: update the model's parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        # Print every 2000 mini-batches\n",
    "        if i % 2000 == 1999:    \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# After training, we want to test how well the model performs on unseen data\n",
    "# We'll compute the accuracy of the model on the test data\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "# We don't need to compute gradients during testing, so we use torch.no_grad() \n",
    "# to disable gradient computation\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        # Get the inputs; data is a list of [inputs, labels]\n",
    "        # Move the inputs and labels to the device\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        # Forward pass: compute the outputs by passing inputs to the model\n",
    "        outputs = net(images)\n",
    "        # Get the predicted class by finding the maximum value \n",
    "        # (since we're using CrossEntropyLoss)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        # Update the total number of images\n",
    "        total += labels.size(0)\n",
    "        # Update the number of correctly predicted images\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "# We will store the vectors in a Python dictionary. \n",
    "# The keys will be the image labels and the values will be the vectors.\n",
    "vectors = {}\n",
    "\n",
    "# We move the model to the CPU for the feature extraction. \n",
    "# This is because we're going to be working with numpy, which can't handle CUDA tensors.\n",
    "net = net.to('cpu')\n",
    "\n",
    "# We don't need to compute gradients during feature extraction, \n",
    "# so we use torch.no_grad() to disable gradient computation.\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        # Get the inputs; data is a list of [inputs, labels]\n",
    "        images, labels = data\n",
    "        # Forward pass: compute the outputs by passing inputs to the model\n",
    "        outputs = net(images)\n",
    "        # For each image in the batch, we store its vector in the dictionary.\n",
    "        for i in range(len(outputs)):\n",
    "            vectors[labels[i].item()] = outputs[i].numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Malco\\mambaforge\\envs\\data\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Malco\\mambaforge\\envs\\data\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the ResNet-50 model architecture\n",
    "net = models.resnet50(pretrained=False)  # Note: pretrained is set to False\n",
    "\n",
    "# Modify the final layer to match CIFAR-10's 10 classes\n",
    "num_ftrs = net.fc.in_features\n",
    "net.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "# Load the saved model weights\n",
    "saved_weights_path = \"C:/Users/Malco/OneDrive/Desktop/Vector Database Project/cifar_net.pth\"\n",
    "net.load_state_dict(torch.load(saved_weights_path))\n",
    "\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: dog\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Get a random image\n",
    "dataiter = iter(trainloader)\n",
    "image, label = next(dataiter)\n",
    "\n",
    "# Function to show image\n",
    "def imshow(img):\n",
    "    img = img.numpy().transpose((1, 2, 0))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "# Display the image\n",
    "imshow(image[0])\n",
    "\n",
    "print(\"Label:\", trainset.classes[label[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_vector = image.view(-1)\n",
    "\n",
    "torch.save(image_vector, 'cifar_vector.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Running on device: cuda:0\n",
      "Model weights loaded successfully and moved to device!\n",
      "Extracted 5000 feature vectors for class 0.\n",
      "Extracted 5000 feature vectors for class 1.\n",
      "Extracted 5000 feature vectors for class 2.\n",
      "Extracted 5000 feature vectors for class 3.\n",
      "Extracted 5000 feature vectors for class 4.\n",
      "Extracted 5000 feature vectors for class 5.\n",
      "Extracted 5000 feature vectors for class 6.\n",
      "Extracted 5000 feature vectors for class 7.\n",
      "Extracted 5000 feature vectors for class 8.\n",
      "Extracted 5000 feature vectors for class 9.\n",
      "Feature vectors serialized and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "\n",
    "# 1. Load the CIFAR-10 dataset\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=0)\n",
    "\n",
    "# Check for GPU availability and set the device accordingly\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on device: {device}\")\n",
    "\n",
    "# 2. Set up the ResNet-50 model structure\n",
    "net = models.resnet50(pretrained=False)\n",
    "num_ftrs = net.fc.in_features\n",
    "net.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "# 3. Load the saved model weights and move the model to the device\n",
    "weights_path = \"cifar_net.pth\"\n",
    "net.load_state_dict(torch.load(weights_path))\n",
    "net.to(device)\n",
    "print(\"Model weights loaded successfully and moved to device!\")\n",
    "\n",
    "# 4. Extract feature vectors for all images in the dataset\n",
    "vectors = {label: [] for label in range(10)}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        outputs = outputs.cpu()\n",
    "        for i in range(len(outputs)):\n",
    "            label = labels[i].item()\n",
    "            vectors[label].append(outputs[i].numpy())\n",
    "\n",
    "# Check the number of vectors extracted for each class\n",
    "for label, vecs in vectors.items():\n",
    "    print(f\"Extracted {len(vecs)} feature vectors for class {label}.\")\n",
    "\n",
    "# 5. Serialize and save the 'vectors' dictionary\n",
    "with open(\"vectors.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectors, f)\n",
    "\n",
    "print(\"Feature vectors serialized and saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vectors serialized and saved to vectors.h5!\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have 'all_vectors' from the previous extraction step\n",
    "\n",
    "# 1. Organize the data for serialization\n",
    "labels = [vec[0] for vec in all_vectors]\n",
    "vectors = [vec[1] for vec in all_vectors]\n",
    "labels_array = np.array(labels)\n",
    "vectors_array = np.array(vectors)\n",
    "\n",
    "# 2. Serialize the feature vectors using HDF5\n",
    "with h5py.File('vectors.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"labels\", data=labels_array)\n",
    "    hf.create_dataset(\"vectors\", data=vectors_array)\n",
    "\n",
    "print(\"Feature vectors serialized and saved to vectors.h5!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "[[-3.7416759   1.5174972   0.4495462   0.9992044   0.5351528  -1.2945983\n",
      "   2.1852105   4.914448   -0.97608423  0.26909238]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "# 1. Load a random CIFAR-10 image\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1, shuffle=True)  # Ensure batch size is 1\n",
    "dataiter = iter(trainloader)\n",
    "single_image, single_label = next(dataiter)\n",
    "\n",
    "\n",
    "# Check for GPU availability and set the device accordingly\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 2. Set up the ResNet-50 model structure and load weights\n",
    "net_single = models.resnet50(pretrained=False)\n",
    "num_ftrs_single = net_single.fc.in_features\n",
    "net_single.fc = nn.Linear(num_ftrs_single, 10)\n",
    "weights_path = \"cifar_net.pth\"  # Assuming the path to your model weights\n",
    "net_single.load_state_dict(torch.load(weights_path))\n",
    "net_single.to(device)\n",
    "net_single.eval()\n",
    "\n",
    "# Extract the feature vector for the single image\n",
    "with torch.no_grad():\n",
    "    single_image = single_image.to(device)\n",
    "    single_output = net_single(single_image)\n",
    "    single_vector = single_output.cpu().numpy()\n",
    "\n",
    "print(single_vector)  # This is the extracted feature vector for your single CIFAR-10 image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0.9999587\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load the feature vectors from 'vectors.h5'\n",
    "with h5py.File('vectors.h5', 'r') as hf:\n",
    "    labels_h5 = hf['labels'][:]\n",
    "    vectors_h5 = hf['vectors'][:]\n",
    "\n",
    "# 2. Compute the cosine similarity for the single_vector against each feature vector in 'vectors.h5'\n",
    "similarities_h5 = cosine_similarity(single_vector, vectors_h5)\n",
    "\n",
    "# 3. Determine the Most Similar Image\n",
    "most_similar_index_h5 = np.argmax(similarities_h5)\n",
    "most_similar_label_h5 = labels_h5[most_similar_index_h5]\n",
    "most_similar_value_h5 = similarities_h5[0][most_similar_index_h5]\n",
    "\n",
    "print(most_similar_label_h5, most_similar_value_h5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
