{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define a transform to normalize the data. The transforms are applied\n",
    "# in the order they are given. First, the image is converted to a tensor,\n",
    "# then it is normalized with mean and standard deviation of 0.5 for all channels.\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Download the CIFAR-10 dataset, apply the transforms, and load it into\n",
    "# a DataLoader for efficient batch processing and shuffling.\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=0)\n",
    "\n",
    "# Define the classes in the CIFAR-10 dataset. These correspond to the labels\n",
    "# of the images in the dataset.\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Load the pretrained ResNet-50 model.\n",
    "net = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze all the parameters of the model, making them untrainable.\n",
    "# This is done because we want to keep the weights of the pre-trained model\n",
    "# and only train the final layer that we will add next.\n",
    "for param in net.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the last fully connected layer of the model with a new one \n",
    "# having the correct number of output features. The new layer's parameters\n",
    "# are not frozen, so they will be learned during training.\n",
    "num_ftrs = net.fc.in_features\n",
    "net.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "# Define a loss function and an optimizer. The loss function is used to measure\n",
    "# how well the model's predictions match the actual labels, and the optimizer\n",
    "# is used to update the model's parameters based on this loss.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Set device to GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move the model to the device (GPU or CPU)\n",
    "net.to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(5):  # Loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get the inputs; data is a list of [inputs, labels]\n",
    "        # Move the inputs and labels to the device\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        # This is necessary because by default, gradients are accumulated\n",
    "        # in backward passes, so we need to clear them at each step\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass: compute the outputs by passing inputs to the model\n",
    "        outputs = net(inputs)\n",
    "        # Compute the loss between the outputs and the ground truth labels\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backward pass: compute the gradients of the loss w.r.t. the model's parameters\n",
    "        loss.backward()\n",
    "        # Perform an optimization step: update the model's parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        # Print every 2000 mini-batches\n",
    "        if i % 2000 == 1999:    \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# After training, we want to test how well the model performs on unseen data\n",
    "# We'll compute the accuracy of the model on the test data\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "# We don't need to compute gradients during testing, so we use torch.no_grad() \n",
    "# to disable gradient computation\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        # Get the inputs; data is a list of [inputs, labels]\n",
    "        # Move the inputs and labels to the device\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        # Forward pass: compute the outputs by passing inputs to the model\n",
    "        outputs = net(images)\n",
    "        # Get the predicted class by finding the maximum value \n",
    "        # (since we're using CrossEntropyLoss)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        # Update the total number of images\n",
    "        total += labels.size(0)\n",
    "        # Update the number of correctly predicted images\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "# We will store the vectors in a Python dictionary. \n",
    "# The keys will be the image labels and the values will be the vectors.\n",
    "vectors = {}\n",
    "\n",
    "# We move the model to the CPU for the feature extraction. \n",
    "# This is because we're going to be working with numpy, which can't handle CUDA tensors.\n",
    "net = net.to('cpu')\n",
    "\n",
    "# We don't need to compute gradients during feature extraction, \n",
    "# so we use torch.no_grad() to disable gradient computation.\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        # Get the inputs; data is a list of [inputs, labels]\n",
    "        images, labels = data\n",
    "        # Forward pass: compute the outputs by passing inputs to the model\n",
    "        outputs = net(images)\n",
    "        # For each image in the batch, we store its vector in the dictionary.\n",
    "        for i in range(len(outputs)):\n",
    "            vectors[labels[i].item()] = outputs[i].numpy()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
